{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import functools\n",
    "import numpy as np\n",
    "import optax\n",
    "import tqdm\n",
    "import tree\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from absl import logging\n",
    "from typing import Any\n",
    "\n",
    "from data import utm_data_generator as utm_dg_lib\n",
    "from data import chomsky_data_generator as chomsky_sampler_lib\n",
    "from helpers import make_chomsky_generator, utm_data_generator, make_model, init_params, save_params, evaluate_transformer_decoder, CHOMSKY_ALPHABET_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "\n",
    "# Follows the paper's parameters\n",
    "TRAINING_STEPS = 2000\n",
    "EXECUTION_STEPS = 1000\n",
    "USE_DELIMITERS = True\n",
    "MEMORY_SIZE = 200\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Use Markov = [True, False]\n",
    "USE_MARKOV = True\n",
    "# Model Size = [\"small\", \"medium\", \"large\"]\n",
    "MODEL_SIZE = \"large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_loss_fn(model: hk.Transformed) -> Any:\n",
    "  \"\"\"Returns the loss function for update_parameters.\"\"\"\n",
    "\n",
    "  def loss_fn(\n",
    "      params: hk.Params,\n",
    "      sequences: jax.Array,\n",
    "      mask: jax.Array,\n",
    "  ) -> jnp.float32:\n",
    "    \"\"\"Returns the loss for the model and the last state.\n",
    "\n",
    "    Args:\n",
    "      params: The parameters of the model, usually a neural network.\n",
    "      sequences: The input of sequences to evaluate. See neural_predictors.py.\n",
    "      mask: A binary array, True (1's) denote where to skip computing the loss.\n",
    "    \"\"\"\n",
    "    # This code computes the loss for a transformer decoder model:\n",
    "    # 1. Apply the model to get log probabilities (conditionals) for each token\n",
    "    conditionals = model.apply(\n",
    "        params=params,\n",
    "        targets=sequences,\n",
    "        rng=None,\n",
    "    )\n",
    "    # 2. Extract the log probabilities of the actual tokens that appeared in the sequence\n",
    "    # by using take_along_axis to select the probability corresponding to each token\n",
    "    true_conditionals = jnp.take_along_axis(\n",
    "        conditionals, sequences[..., None], axis=-1\n",
    "    )[..., 0]\n",
    "    # 3. Apply the mask to zero out log probabilities where we should skip computing loss (e.g., for padding tokens)\n",
    "    true_conditionals = jnp.where(mask, 0.0, true_conditionals)\n",
    "    # 4. Sum the log probabilities across the sequence dimension to get log likelihood per batch\n",
    "    marginals = jnp.sum(true_conditionals, axis=1)  # Shape (B,).\n",
    "    # 5. Return the negative mean log likelihood as the loss (for minimization)\n",
    "    return -jnp.mean(marginals)\n",
    "\n",
    "  return loss_fn\n",
    "\n",
    "\n",
    "@functools.partial(\n",
    "    jax.jit, static_argnames=('optimizer', 'grad_fn', 'normalize_gradients')\n",
    ")\n",
    "def _update_parameters(\n",
    "    params: hk.Params,\n",
    "    opt_state: optax.OptState,\n",
    "    sequences: jax.Array,\n",
    "    mask: jax.Array,\n",
    "    grad_fn: Any,\n",
    "    optimizer: optax.GradientTransformation,\n",
    "    normalize_gradients: bool = True,\n",
    ") -> tuple[hk.Params, optax.OptState, dict[str, Any]]:\n",
    "  \"\"\"Returns updated params and extra logs (like loss, last state etc).\n",
    "\n",
    "  Backpropagation is done on the whole sequence. The whole function is jitted.\n",
    "\n",
    "  Args:\n",
    "    params: The current parameters of the network.\n",
    "    opt_state: The optimizer state.\n",
    "    sequences: The input of sequences to evaluate. See base_predictor.py.\n",
    "    mask: A binary array, True (1's) denote where to skip computing the loss.\n",
    "    grad_fn: A gradient function, which takes some parameters, a random seed,\n",
    "      the data to compute the gradient on, and an initial state for the\n",
    "      predictor. It returns the gradient of the parameters for this batch of\n",
    "      data, and extra values.\n",
    "    optimizer: An optax optimizer.\n",
    "    normalize_gradients: Whether to divide the gradients by the length of the\n",
    "      sequences, or keep them as is. Using this option guarantees to have the\n",
    "      same scale across various sequence lengths, and therefore tasks.\n",
    "  \"\"\"\n",
    "  loss, grad = grad_fn(params, sequences, mask)\n",
    "  if normalize_gradients:\n",
    "    length_sequence = float(sequences.shape[1])\n",
    "    grad = tree.map_structure(lambda x: x / length_sequence, grad)\n",
    "  updates, new_opt_state = optimizer.update(grad, opt_state)\n",
    "  new_params = optax.apply_updates(params, updates)\n",
    "\n",
    "  log_dict = {\n",
    "      'loss': loss,\n",
    "      'grad_norm_unclipped': optax.global_norm(grad),\n",
    "  }\n",
    "\n",
    "  return new_params, new_opt_state, log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer_decoder(\n",
    "    data_generator: utm_dg_lib.UTMDataGenerator,\n",
    "    training_steps: int,\n",
    "    log_every: int,\n",
    "    batch_size: int,\n",
    "    use_tqdm: bool = True,\n",
    "    with_markov: bool = False,\n",
    "    size: str = \"large\",\n",
    "    eval_data_generator: chomsky_sampler_lib.ChomskyDataGenerator = None,\n",
    ") -> tuple[hk.Params, float, list[float], list[float], list[float]]:\n",
    "    \"\"\"Trains a neural network on some synthetic data.\n",
    "\n",
    "    We train a decoder-only transformer on batches, minimizing the log-loss\n",
    "    objective. The exact architecture can be modified using the TransformerConfig\n",
    "    object (defined in models/transformer.py)\n",
    "\n",
    "    Args:\n",
    "      data_generator: Used to generate batches of data to train on.\n",
    "      training_steps: Number of batches to train on.\n",
    "      log_every: How often to log the loss. If negative or 0, no log at all.\n",
    "      batch_size: The number of sequences in a batch.\n",
    "      use_tqdm: Whether to use a progress bar or not.\n",
    "\n",
    "    Returns:\n",
    "      The final loss, and final parameters.\n",
    "    \"\"\"\n",
    "    print(\"Vocab Size:\", data_generator.feature_size)\n",
    "    print(\"Model Size:\", size)\n",
    "    print(\"Batch Size:\", batch_size)\n",
    "    print(\"With Markov:\", with_markov)\n",
    "    model = make_model(data_generator, size)\n",
    "\n",
    "    params = init_params(model, data_generator, batch_size)\n",
    "\n",
    "    # Make gradient function.\n",
    "    loss_fn = _make_loss_fn(model)\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=False)\n",
    "\n",
    "    # Make optimizer, to apply the gradients.\n",
    "    optimizer = optax.adam(learning_rate=1e-4)\n",
    "    opt_state = optimizer.init(params)\n",
    "\n",
    "    logging.info(\"Initialization done, starting training...\")\n",
    "    \n",
    "    last_loss = 0.0\n",
    "    default_mask = lambda x: np.ones(x.shape[:2], dtype=bool)\n",
    "    eval_losses = []\n",
    "    eval_accs = []\n",
    "    eval_final_accs = []\n",
    "\n",
    "    for step in tqdm.trange(training_steps, disable=not use_tqdm):\n",
    "        batch, log_dict = data_generator.sample(with_markov=with_markov)\n",
    "        # Transform one-hots to integer tokens.\n",
    "        batch = np.argmax(batch, axis=-1)\n",
    "        if \"loss_mask\" in log_dict:\n",
    "            loss_mask = log_dict[\"loss_mask\"]\n",
    "        else:\n",
    "            loss_mask = default_mask(batch)\n",
    "\n",
    "        params, opt_state, logs = _update_parameters(\n",
    "            params=params,\n",
    "            opt_state=opt_state,\n",
    "            sequences=batch,\n",
    "            grad_fn=grad_fn,\n",
    "            optimizer=optimizer,\n",
    "            mask=loss_mask,\n",
    "        )\n",
    "        \n",
    "        if log_every > 0 and step % log_every == 0:\n",
    "            logging.info(\n",
    "                \"Step %d, Loss (avg cumulative nats) %f, Grad norm %f\",\n",
    "                step,\n",
    "                logs[\"loss\"],\n",
    "                logs[\"grad_norm_unclipped\"],\n",
    "            )\n",
    "        \n",
    "        if step % (log_every * 10) == 0 and eval_data_generator is not None:\n",
    "            last_loss = logs[\"loss\"]\n",
    "            eval_loss, eval_acc, eval_final_acc = evaluate_transformer_decoder(\n",
    "                eval_data_generator, params, data_generator, size=size\n",
    "            )\n",
    "            eval_losses.append(eval_loss)\n",
    "            eval_accs.append(eval_acc)\n",
    "            eval_final_accs.append(eval_final_acc)\n",
    "            print(\n",
    "                f\"Step {step}, Eval acc: {eval_acc}, Eval final acc: {eval_final_acc}\"\n",
    "            )\n",
    "\n",
    "    return params, last_loss, eval_losses, eval_accs, eval_final_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 128\n",
      "Model Size: large\n",
      "Batch Size: 32\n",
      "With Markov: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chomsky Task:  even_pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:13<1:27:10,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Eval acc: 0.03209381178021431, Eval final acc: 0.03209034353494644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 100/2000 [01:42<29:49,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chomsky Task:  even_pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 104/2000 [01:57<1:10:13,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100, Eval acc: 0.45093798637390137, Eval final acc: 0.45092812180519104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 200/2000 [03:27<28:17,  1.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chomsky Task:  even_pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 204/2000 [03:42<1:06:18,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200, Eval acc: 0.4732603430747986, Eval final acc: 0.4732317328453064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 300/2000 [05:12<27:11,  1.04it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chomsky Task:  even_pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 304/2000 [05:26<1:00:14,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300, Eval acc: 0.47800058126449585, Eval final acc: 0.47799596190452576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 400/2000 [06:55<26:17,  1.01it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chomsky Task:  even_pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 404/2000 [07:09<56:01,  2.11s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400, Eval acc: 0.4773560166358948, Eval final acc: 0.4773377776145935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 500/2000 [09:06<32:05,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chomsky Task:  even_pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 504/2000 [09:22<1:01:19,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500, Eval acc: 0.4802875518798828, Eval final acc: 0.480264812707901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 600/2000 [11:22<37:14,  1.60s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chomsky Task:  even_pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 604/2000 [11:39<1:03:29,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600, Eval acc: 0.4819555878639221, Eval final acc: 0.4819667339324951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 700/2000 [13:24<20:41,  1.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chomsky Task:  even_pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 704/2000 [13:40<49:45,  2.30s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 700, Eval acc: 0.46608766913414, Eval final acc: 0.46606379747390747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 800/2000 [15:13<20:17,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chomsky Task:  even_pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 804/2000 [15:26<40:56,  2.05s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 800, Eval acc: 0.4804672598838806, Eval final acc: 0.4804416298866272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 810/2000 [15:30<22:47,  1.15s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      3\u001b[39m utm_generator = utm_data_generator(\n\u001b[32m      4\u001b[39m     rng,\n\u001b[32m      5\u001b[39m     maximum_steps=EXECUTION_STEPS,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     batch_size=BATCH_SIZE,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m chomsky_generator = make_chomsky_generator(rng, use_delimiters=USE_DELIMITERS)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m params, loss, eval_losses, eval_accs, eval_final_accs = \u001b[43mtrain_transformer_decoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_generator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mutm_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTRAINING_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_markov\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUSE_MARKOV\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_data_generator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchomsky_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m logging.info(\u001b[33m\"\u001b[39m\u001b[33mFinal loss: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[33m\"\u001b[39m, loss)\n\u001b[32m     25\u001b[39m SUFFIX = \u001b[33m\"\u001b[39m\u001b[33mmarkov\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m USE_MARKOV \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33moriginal\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mtrain_transformer_decoder\u001b[39m\u001b[34m(data_generator, training_steps, log_every, batch_size, use_tqdm, with_markov, size, eval_data_generator)\u001b[39m\n\u001b[32m     49\u001b[39m eval_final_accs = []\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m tqdm.trange(training_steps, disable=\u001b[38;5;129;01mnot\u001b[39;00m use_tqdm):\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     batch, log_dict = \u001b[43mdata_generator\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwith_markov\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwith_markov\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     \u001b[38;5;66;03m# Transform one-hots to integer tokens.\u001b[39;00m\n\u001b[32m     54\u001b[39m     batch = np.argmax(batch, axis=-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/UTM_NEW/Learning-UTM/data/data_generator.py:126\u001b[39m, in \u001b[36mDataGenerator.sample\u001b[39m\u001b[34m(self, with_markov)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Samples a batch with randomly sampled true parameters.\u001b[39;00m\n\u001b[32m    116\u001b[39m \n\u001b[32m    117\u001b[39m \u001b[33;03mReturns:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    121\u001b[39m \u001b[33;03m    sequence.\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    123\u001b[39m params = \u001b[38;5;28mself\u001b[39m.sample_params(\n\u001b[32m    124\u001b[39m     sample_size=\u001b[38;5;28mself\u001b[39m._batch_size, with_markov=with_markov\n\u001b[32m    125\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m sequences, categorical_probs, extra = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msample_from_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m log_dict = {\n\u001b[32m    128\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcategorical_probs\u001b[39m\u001b[33m\"\u001b[39m: categorical_probs,\n\u001b[32m    129\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: params,\n\u001b[32m    130\u001b[39m }\n\u001b[32m    131\u001b[39m log_dict.update(extra)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/UTM_NEW/Learning-UTM/data/utm_data_generator.py:178\u001b[39m, in \u001b[36mUTMDataGenerator.sample_from_params\u001b[39m\u001b[34m(self, params)\u001b[39m\n\u001b[32m    175\u001b[39m   masks.append(mask)\n\u001b[32m    177\u001b[39m loss_mask = jnp.asarray(masks)\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m output = \u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m output = jnn.one_hot(output, num_classes=\u001b[38;5;28mself\u001b[39m.feature_size, dtype=jnp.uint8)\n\u001b[32m    180\u001b[39m \u001b[38;5;66;03m# In this case, the probabilities for the categorical distribution are\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[38;5;66;03m# delta, meaning there is only one possible next token. They are equal to\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[38;5;66;03m# the one hot output itself.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nnsi/lib/python3.13/site-packages/jax/_src/numpy/lax_numpy.py:5721\u001b[39m, in \u001b[36masarray\u001b[39m\u001b[34m(a, dtype, order, copy, device)\u001b[39m\n\u001b[32m   5719\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5720\u001b[39m   dtype = dtypes.canonicalize_dtype(dtype, allow_extended_dtype=\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5721\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nnsi/lib/python3.13/site-packages/jax/_src/numpy/lax_numpy.py:5555\u001b[39m, in \u001b[36marray\u001b[39m\u001b[34m(object, dtype, copy, order, ndmin, device)\u001b[39m\n\u001b[32m   5553\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   5554\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected input type for array: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m5555\u001b[39m out_array: Array = \u001b[43mlax_internal\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_convert_element_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5556\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweak_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweak_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharding\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ndmin > np.ndim(out_array):\n\u001b[32m   5558\u001b[39m   out_array = lax.expand_dims(out_array, \u001b[38;5;28mrange\u001b[39m(ndmin - np.ndim(out_array)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nnsi/lib/python3.13/site-packages/jax/_src/lax/lax.py:1614\u001b[39m, in \u001b[36m_convert_element_type\u001b[39m\u001b[34m(operand, new_dtype, weak_type, sharding, warn_on_complex_to_real_cast)\u001b[39m\n\u001b[32m   1612\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m operand\n\u001b[32m   1613\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1614\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_element_type_p\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1615\u001b[39m \u001b[43m      \u001b[49m\u001b[43moperand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweak_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mweak_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1616\u001b[39m \u001b[43m      \u001b[49m\u001b[43msharding\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharding\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nnsi/lib/python3.13/site-packages/jax/_src/core.py:502\u001b[39m, in \u001b[36mPrimitive.bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **params):\n\u001b[32m    501\u001b[39m   args = args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.skip_canonicalization \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(canonicalize_value, args)\n\u001b[32m--> \u001b[39m\u001b[32m502\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_true_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nnsi/lib/python3.13/site-packages/jax/_src/core.py:520\u001b[39m, in \u001b[36mPrimitive._true_bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    518\u001b[39m trace_ctx.set_trace(eval_trace)\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    522\u001b[39m   trace_ctx.set_trace(prev_trace)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nnsi/lib/python3.13/site-packages/jax/_src/lax/lax.py:4701\u001b[39m, in \u001b[36m_convert_element_type_bind_with_trace\u001b[39m\u001b[34m(trace, args, params)\u001b[39m\n\u001b[32m   4699\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_convert_element_type_bind_with_trace\u001b[39m(trace, args, params):\n\u001b[32m   4700\u001b[39m   sharding = params[\u001b[33m'\u001b[39m\u001b[33msharding\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m4701\u001b[39m   operand = \u001b[43mcore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPrimitive\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_element_type_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4702\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m sharding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m sharding._is_concrete:\n\u001b[32m   4703\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m core.set_current_trace(trace):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nnsi/lib/python3.13/site-packages/jax/_src/core.py:525\u001b[39m, in \u001b[36mPrimitive.bind_with_trace\u001b[39m\u001b[34m(self, trace, args, params)\u001b[39m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nnsi/lib/python3.13/site-packages/jax/_src/core.py:1029\u001b[39m, in \u001b[36mEvalTrace.process_primitive\u001b[39m\u001b[34m(self, primitive, args, params)\u001b[39m\n\u001b[32m   1027\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m primitive.bind_with_trace(arg._trace, args, params)\n\u001b[32m   1028\u001b[39m check_eval_args(args)\n\u001b[32m-> \u001b[39m\u001b[32m1029\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nnsi/lib/python3.13/site-packages/jax/_src/dispatch.py:88\u001b[39m, in \u001b[36mapply_primitive\u001b[39m\u001b[34m(prim, *args, **params)\u001b[39m\n\u001b[32m     86\u001b[39m prev = lib.jax_jit.swap_thread_local_state_disable_jit(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m   outs = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     90\u001b[39m   lib.jax_jit.swap_thread_local_state_disable_jit(prev)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed=1)\n",
    "\n",
    "utm_generator = utm_data_generator(\n",
    "    rng,\n",
    "    maximum_steps=EXECUTION_STEPS,\n",
    "    maximum_program_length=100,\n",
    "    memory_size=MEMORY_SIZE,\n",
    "    alphabet_size=CHOMSKY_ALPHABET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "chomsky_generator = make_chomsky_generator(rng, use_delimiters=USE_DELIMITERS)\n",
    "\n",
    "def training_loop():\n",
    "    model_sizes = [\"small\", \"medium\", \"large\"]\n",
    "    use_markovs = [True, False]\n",
    "    for use_markov in use_markovs:\n",
    "        for model_size in model_sizes:\n",
    "            params, loss, eval_losses, eval_accs, eval_final_accs = train_transformer_decoder(\n",
    "                data_generator=utm_generator,\n",
    "                training_steps=TRAINING_STEPS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                log_every=10,\n",
    "                with_markov=use_markov,\n",
    "                size=model_size,\n",
    "                eval_data_generator=chomsky_generator,\n",
    "            )\n",
    "            logging.info(\"Final loss: %f\", loss)\n",
    "\n",
    "            SUFFIX = \"markov\" if USE_MARKOV else \"original\"\n",
    "\n",
    "            file_name = f\"params_{SUFFIX}_transformer_{MODEL_SIZE}.npz\"\n",
    "            save_params(params, file_name)\n",
    "\n",
    "            logging.info(f\"Parameters saved in file {file_name}\")\n",
    "\n",
    "            # Create a pandas DataFrame from the evaluation metrics\n",
    "            eval_data = {\n",
    "                \"eval_losses\": eval_losses,\n",
    "                \"eval_accs\": eval_accs,\n",
    "                \"eval_final_accs\": eval_final_accs,\n",
    "            }\n",
    "            eval_df = pd.DataFrame(eval_data)\n",
    "\n",
    "            # Save the DataFrame to a CSV file\n",
    "            metrics_name = f\"metrics_{SUFFIX}_transformer_{MODEL_SIZE}.csv\"\n",
    "            eval_df.to_csv(metrics_name, index=False)\n",
    "\n",
    "            logging.info(\"Evaluation metrics saved to evaluation_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting eval accs and eval final accs\n",
    "# plt.plot(eval_accs, label=\"avg\", color=\"red\")\n",
    "# plt.plot(eval_final_accs, label=\"final\", color=\"blue\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chomsky Task:  even_pairs\n",
      "0.3698835 0.3698499\n"
     ]
    }
   ],
   "source": [
    "# For testing only. Chomsky evaluation is done in run_chomsky_experiments.ipynb\n",
    "# regret, total_accuracy, total_final_accuracy = evaluate_transformer_decoder(\n",
    "#     chomsky_generator, params, utm_generator, num_batches=10, size=MODEL_SIZE\n",
    "# )\n",
    "# print(total_accuracy, total_final_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
