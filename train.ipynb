{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import functools\n",
    "import numpy as np\n",
    "import optax\n",
    "import tqdm\n",
    "import tree\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from absl import logging\n",
    "from typing import Any\n",
    "\n",
    "from data import utm_data_generator as utm_dg_lib\n",
    "from data import chomsky_data_generator as chomsky_sampler_lib\n",
    "from helpers import make_chomsky_generator, utm_data_generator, make_model, init_params, save_params, evaluate_transformer_decoder, CHOMSKY_ALPHABET_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "\n",
    "class SAMPLE_TYPE:\n",
    "    ORIGINAL = 0\n",
    "    MARKOV = 1\n",
    "    RANDOM = 2\n",
    "\n",
    "# Follows the paper's parameters\n",
    "TRAINING_STEPS = 2000 # not really used in training loop\n",
    "EXECUTION_STEPS = 1000\n",
    "USE_DELIMITERS = True\n",
    "MEMORY_SIZE = 200\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_loss_fn(model: hk.Transformed) -> Any:\n",
    "  \"\"\"Returns the loss function for update_parameters.\"\"\"\n",
    "\n",
    "  def loss_fn(\n",
    "      params: hk.Params,\n",
    "      sequences: jax.Array,\n",
    "      mask: jax.Array,\n",
    "  ) -> jnp.float32:\n",
    "    \"\"\"Returns the loss for the model and the last state.\n",
    "\n",
    "    Args:\n",
    "      params: The parameters of the model, usually a neural network.\n",
    "      sequences: The input of sequences to evaluate. See neural_predictors.py.\n",
    "      mask: A binary array, True (1's) denote where to skip computing the loss.\n",
    "    \"\"\"\n",
    "    # This code computes the loss for a transformer decoder model:\n",
    "    # 1. Apply the model to get log probabilities (conditionals) for each token\n",
    "    conditionals = model.apply(\n",
    "        params=params,\n",
    "        targets=sequences,\n",
    "        rng=None,\n",
    "    )\n",
    "    # 2. Extract the log probabilities of the actual tokens that appeared in the sequence\n",
    "    # by using take_along_axis to select the probability corresponding to each token\n",
    "    true_conditionals = jnp.take_along_axis(\n",
    "        conditionals, sequences[..., None], axis=-1\n",
    "    )[..., 0]\n",
    "    # 3. Apply the mask to zero out log probabilities where we should skip computing loss (e.g., for padding tokens)\n",
    "    true_conditionals = jnp.where(mask, 0.0, true_conditionals)\n",
    "    # 4. Sum the log probabilities across the sequence dimension to get log likelihood per batch\n",
    "    marginals = jnp.sum(true_conditionals, axis=1)  # Shape (B,).\n",
    "    # 5. Return the negative mean log likelihood as the loss (for minimization)\n",
    "    return -jnp.mean(marginals)\n",
    "\n",
    "  return loss_fn\n",
    "\n",
    "\n",
    "@functools.partial(\n",
    "    jax.jit, static_argnames=('optimizer', 'grad_fn', 'normalize_gradients')\n",
    ")\n",
    "def _update_parameters(\n",
    "    params: hk.Params,\n",
    "    opt_state: optax.OptState,\n",
    "    sequences: jax.Array,\n",
    "    mask: jax.Array,\n",
    "    grad_fn: Any,\n",
    "    optimizer: optax.GradientTransformation,\n",
    "    normalize_gradients: bool = True,\n",
    ") -> tuple[hk.Params, optax.OptState, dict[str, Any]]:\n",
    "  \"\"\"Returns updated params and extra logs (like loss, last state etc).\n",
    "\n",
    "  Backpropagation is done on the whole sequence. The whole function is jitted.\n",
    "\n",
    "  Args:\n",
    "    params: The current parameters of the network.\n",
    "    opt_state: The optimizer state.\n",
    "    sequences: The input of sequences to evaluate. See base_predictor.py.\n",
    "    mask: A binary array, True (1's) denote where to skip computing the loss.\n",
    "    grad_fn: A gradient function, which takes some parameters, a random seed,\n",
    "      the data to compute the gradient on, and an initial state for the\n",
    "      predictor. It returns the gradient of the parameters for this batch of\n",
    "      data, and extra values.\n",
    "    optimizer: An optax optimizer.\n",
    "    normalize_gradients: Whether to divide the gradients by the length of the\n",
    "      sequences, or keep them as is. Using this option guarantees to have the\n",
    "      same scale across various sequence lengths, and therefore tasks.\n",
    "  \"\"\"\n",
    "  loss, grad = grad_fn(params, sequences, mask)\n",
    "  if normalize_gradients:\n",
    "    length_sequence = float(sequences.shape[1])\n",
    "    grad = tree.map_structure(lambda x: x / length_sequence, grad)\n",
    "  updates, new_opt_state = optimizer.update(grad, opt_state)\n",
    "  new_params = optax.apply_updates(params, updates)\n",
    "\n",
    "  log_dict = {\n",
    "      'loss': loss,\n",
    "      'grad_norm_unclipped': optax.global_norm(grad),\n",
    "  }\n",
    "\n",
    "  return new_params, new_opt_state, log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer_decoder(\n",
    "    data_generator: utm_dg_lib.UTMDataGenerator,\n",
    "    training_steps: int,\n",
    "    log_every: int,\n",
    "    batch_size: int,\n",
    "    use_tqdm: bool = True,\n",
    "    with_markov: bool = False,\n",
    "    size: str = \"large\",\n",
    "    eval_data_generator: chomsky_sampler_lib.ChomskyDataGenerator = None,\n",
    ") -> tuple[hk.Params, float, list[float], list[float], list[float]]:\n",
    "    \"\"\"Trains a neural network on some synthetic data.\n",
    "\n",
    "    We train a decoder-only transformer on batches, minimizing the log-loss\n",
    "    objective. The exact architecture can be modified using the TransformerConfig\n",
    "    object (defined in models/transformer.py)\n",
    "\n",
    "    Args:\n",
    "      data_generator: Used to generate batches of data to train on.\n",
    "      training_steps: Number of batches to train on.\n",
    "      log_every: How often to log the loss. If negative or 0, no log at all.\n",
    "      batch_size: The number of sequences in a batch.\n",
    "      use_tqdm: Whether to use a progress bar or not.\n",
    "\n",
    "    Returns:\n",
    "      The final loss, and final parameters.\n",
    "    \"\"\"\n",
    "    print(\"Vocab Size:\", data_generator.feature_size)\n",
    "    print(\"Model Size:\", size)\n",
    "    print(\"Batch Size:\", batch_size)\n",
    "    print(\"With Markov:\", with_markov)\n",
    "    model = make_model(data_generator, size)\n",
    "\n",
    "    params = init_params(model, data_generator, batch_size)\n",
    "\n",
    "    # Make gradient function.\n",
    "    loss_fn = _make_loss_fn(model)\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=False)\n",
    "\n",
    "    # Make optimizer, to apply the gradients.\n",
    "    optimizer = optax.adam(learning_rate=1e-4)\n",
    "    opt_state = optimizer.init(params)\n",
    "\n",
    "    logging.info(\"Initialization done, starting training...\")\n",
    "\n",
    "    last_loss = 0.0\n",
    "    default_mask = lambda x: np.ones(x.shape[:2], dtype=bool)\n",
    "    eval_losses = []\n",
    "    eval_accs = []\n",
    "    eval_final_accs = []\n",
    "\n",
    "    for step in tqdm.trange(training_steps, disable=not use_tqdm):\n",
    "        batch, log_dict = data_generator.sample(with_markov=with_markov)\n",
    "        # Transform one-hots to integer tokens.\n",
    "        batch = np.argmax(batch, axis=-1)\n",
    "        if \"loss_mask\" in log_dict:\n",
    "            loss_mask = log_dict[\"loss_mask\"]\n",
    "        else:\n",
    "            loss_mask = default_mask(batch)\n",
    "\n",
    "        params, opt_state, logs = _update_parameters(\n",
    "            params=params,\n",
    "            opt_state=opt_state,\n",
    "            sequences=batch,\n",
    "            grad_fn=grad_fn,\n",
    "            optimizer=optimizer,\n",
    "            mask=loss_mask,\n",
    "        )\n",
    "\n",
    "        if log_every > 0 and step % log_every == 0:\n",
    "            logging.info(\n",
    "                \"Step %d, Loss (avg cumulative nats) %f, Grad norm %f\",\n",
    "                step,\n",
    "                logs[\"loss\"],\n",
    "                logs[\"grad_norm_unclipped\"],\n",
    "            )\n",
    "\n",
    "        if step % (log_every * 10) == 0 and eval_data_generator is not None:\n",
    "            last_loss = logs[\"loss\"]\n",
    "            eval_loss, eval_acc, eval_final_acc = evaluate_transformer_decoder(\n",
    "                eval_data_generator, params, data_generator, size=size\n",
    "            )\n",
    "            eval_losses.append(eval_loss)\n",
    "            eval_accs.append(eval_acc)\n",
    "            eval_final_accs.append(eval_final_acc)\n",
    "            print(\n",
    "                f\"Step {step}, Eval acc: {eval_acc}, Eval final acc: {eval_final_acc}\"\n",
    "            )\n",
    "\n",
    "    return params, last_loss, eval_losses, eval_accs, eval_final_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 128\n",
      "Model Size: small\n",
      "Batch Size: 32\n",
      "With Markov: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 128\n",
      "Model Size: medium\n",
      "Batch Size: 32\n",
      "With Markov: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 128\n",
      "Model Size: large\n",
      "Batch Size: 32\n",
      "With Markov: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 128\n",
      "Model Size: small\n",
      "Batch Size: 32\n",
      "With Markov: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chomsky Task:  even_pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/20000 [00:08<3:17:36,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Eval acc: 0.008060423657298088, Eval final acc: 0.008061978965997696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 100/20000 [00:11<13:14, 25.05it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chomsky Task:  even_pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 110/20000 [00:15<57:23,  5.78it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100, Eval acc: 0.015095042996108532, Eval final acc: 0.015102459117770195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 198/20000 [00:18<13:32, 24.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chomsky Task:  even_pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 200/20000 [00:19<32:06, 10.28it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 77\u001b[39m\n\u001b[32m     73\u001b[39m                 eval_df.to_csv(metrics_name, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     75\u001b[39m             logging.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEvaluation metrics saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mtraining_loop\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sampling_type == SAMPLE_TYPE.RANDOM:\n\u001b[32m     37\u001b[39m     training_steps = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m params, loss, eval_losses, eval_accs, eval_final_accs = \u001b[43mtrain_transformer_decoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_generator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mutm_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_markov\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampling_type\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mSAMPLE_TYPE\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMARKOV\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_data_generator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchomsky_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m logging.info(\u001b[33m\"\u001b[39m\u001b[33mFinal loss: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[33m\"\u001b[39m, loss)\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sampling_type == SAMPLE_TYPE.ORIGINAL:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 79\u001b[39m, in \u001b[36mtrain_transformer_decoder\u001b[39m\u001b[34m(data_generator, training_steps, log_every, batch_size, use_tqdm, with_markov, size, eval_data_generator)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m step % (log_every * \u001b[32m10\u001b[39m) == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m eval_data_generator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     78\u001b[39m     last_loss = logs[\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     eval_loss, eval_acc, eval_final_acc = \u001b[43mevaluate_transformer_decoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_data_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     eval_losses.append(eval_loss)\n\u001b[32m     83\u001b[39m     eval_accs.append(eval_acc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/UTM_NEW/Learning-UTM/helpers.py:135\u001b[39m, in \u001b[36mevaluate_transformer_decoder\u001b[39m\u001b[34m(chomsky_data_generator, params, training_data_generator, num_batches, size)\u001b[39m\n\u001b[32m    132\u001b[39m total_final_accuracy = \u001b[32m0.0\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     batch, log_dict = \u001b[43mchomsky_data_generator\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m     batch = np.argmax(batch, axis=-\u001b[32m1\u001b[39m)\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minput_locations\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m log_dict:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/UTM_NEW/Learning-UTM/data/data_generator.py:126\u001b[39m, in \u001b[36mDataGenerator.sample\u001b[39m\u001b[34m(self, with_markov)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Samples a batch with randomly sampled true parameters.\u001b[39;00m\n\u001b[32m    116\u001b[39m \n\u001b[32m    117\u001b[39m \u001b[33;03mReturns:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    121\u001b[39m \u001b[33;03m    sequence.\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    123\u001b[39m params = \u001b[38;5;28mself\u001b[39m.sample_params(\n\u001b[32m    124\u001b[39m     sample_size=\u001b[38;5;28mself\u001b[39m._batch_size, with_markov=with_markov\n\u001b[32m    125\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m sequences, categorical_probs, extra = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msample_from_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m log_dict = {\n\u001b[32m    128\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcategorical_probs\u001b[39m\u001b[33m\"\u001b[39m: categorical_probs,\n\u001b[32m    129\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: params,\n\u001b[32m    130\u001b[39m }\n\u001b[32m    131\u001b[39m log_dict.update(extra)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/UTM_NEW/Learning-UTM/data/chomsky_data_generator.py:287\u001b[39m, in \u001b[36mChomskyDataGenerator.sample_from_params\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    282\u001b[39m rand_int = _sample_randint(\n\u001b[32m    283\u001b[39m     low=np.iinfo(np.int64).min,\n\u001b[32m    284\u001b[39m     high=np.iinfo(np.int64).max,\n\u001b[32m    285\u001b[39m )\n\u001b[32m    286\u001b[39m rng = jax.random.PRNGKey(rand_int)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m s_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_task\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_seq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m s_batch[\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m] = np.array(s_batch[\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    289\u001b[39m s_batch[\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m] = np.array(s_batch[\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nnsi/lib/python3.13/site-packages/jax/_src/pjit.py:339\u001b[39m, in \u001b[36m_cpp_pjit.<locals>.cache_miss\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.no_tracing.value:\n\u001b[32m    335\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mre-tracing function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjit_info.fun_sourceinfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    336\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33m`jit`, but \u001b[39m\u001b[33m'\u001b[39m\u001b[33mno_tracing\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is set\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    338\u001b[39m (outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked, executable,\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m  pgle_profiler) = \u001b[43m_python_pjit_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m maybe_fastpath_data = _get_fastpath_data(\n\u001b[32m    342\u001b[39m     executable, out_tree, args_flat, out_flat, attrs_tracked, jaxpr.effects,\n\u001b[32m    343\u001b[39m     jaxpr.consts, jit_info.abstracted_axes,\n\u001b[32m    344\u001b[39m     pgle_profiler)\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outs, maybe_fastpath_data, _need_to_rebuild_with_fdo(pgle_profiler)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nnsi/lib/python3.13/site-packages/jax/_src/pjit.py:194\u001b[39m, in \u001b[36m_python_pjit_helper\u001b[39m\u001b[34m(fun, jit_info, *args, **kwargs)\u001b[39m\n\u001b[32m    192\u001b[39m   args_flat = \u001b[38;5;28mmap\u001b[39m(core.full_lower, args_flat)\n\u001b[32m    193\u001b[39m   core.check_eval_args(args_flat)\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m   out_flat, compiled, profiler = \u001b[43m_pjit_call_impl_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    196\u001b[39m   out_flat = pjit_p.bind(*args_flat, **p.params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nnsi/lib/python3.13/site-packages/jax/_src/pjit.py:1659\u001b[39m, in \u001b[36m_pjit_call_impl_python\u001b[39m\u001b[34m(jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, donated_invars, ctx_mesh, name, keep_unused, inline, compiler_options_kvs, *args)\u001b[39m\n\u001b[32m   1647\u001b[39m compiler_options_kvs = compiler_options_kvs + \u001b[38;5;28mtuple\u001b[39m(pgle_compile_options.items())\n\u001b[32m   1648\u001b[39m \u001b[38;5;66;03m# Passing mutable PGLE profile here since it should be extracted by JAXPR to\u001b[39;00m\n\u001b[32m   1649\u001b[39m \u001b[38;5;66;03m# initialize the fdo_profile compile option.\u001b[39;00m\n\u001b[32m   1650\u001b[39m compiled = \u001b[43m_resolve_and_lower\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1651\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m=\u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_layouts\u001b[49m\u001b[43m=\u001b[49m\u001b[43min_layouts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_layouts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_layouts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mctx_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mctx_mesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1655\u001b[39m \u001b[43m    \u001b[49m\u001b[43minline\u001b[49m\u001b[43m=\u001b[49m\u001b[43minline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlowering_platforms\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlowering_parameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlir\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLoweringParameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1657\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1658\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1659\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1661\u001b[39m \u001b[38;5;66;03m# This check is expensive so only do it if enable_checks is on.\u001b[39;00m\n\u001b[32m   1662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compiled._auto_spmd_lowering \u001b[38;5;129;01mand\u001b[39;00m config.enable_checks.value:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nnsi/lib/python3.13/site-packages/jax/_src/interpreters/pxla.py:2448\u001b[39m, in \u001b[36mMeshComputation.compile\u001b[39m\u001b[34m(self, compiler_options)\u001b[39m\n\u001b[32m   2446\u001b[39m compiler_options_kvs = \u001b[38;5;28mself\u001b[39m._compiler_options_kvs + t_compiler_options\n\u001b[32m   2447\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._executable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m compiler_options_kvs:\n\u001b[32m-> \u001b[39m\u001b[32m2448\u001b[39m   executable = \u001b[43mUnloadedMeshExecutable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_hlo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2449\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_hlo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompile_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2450\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2451\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m compiler_options_kvs:\n\u001b[32m   2452\u001b[39m     \u001b[38;5;28mself\u001b[39m._executable = executable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nnsi/lib/python3.13/site-packages/jax/_src/interpreters/pxla.py:2967\u001b[39m, in \u001b[36mUnloadedMeshExecutable.from_hlo\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   2964\u001b[39m       \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   2966\u001b[39m util.test_event(\u001b[33m\"\u001b[39m\u001b[33mpxla_cached_compilation\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2967\u001b[39m xla_executable = \u001b[43m_cached_compilation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhlo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspmd_lowering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtuple_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_spmd_lowering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_prop_to_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_prop_to_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpmap_nreps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2973\u001b[39m orig_out_shardings = out_shardings\n\u001b[32m   2975\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m auto_spmd_lowering:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nnsi/lib/python3.13/site-packages/jax/_src/interpreters/pxla.py:2758\u001b[39m, in \u001b[36m_cached_compilation\u001b[39m\u001b[34m(computation, name, mesh, spmd_lowering, tuple_args, auto_spmd_lowering, allow_prop_to_inputs, allow_prop_to_outputs, host_callbacks, backend, da, pmap_nreps, compiler_options_kvs, pgle_profiler)\u001b[39m\n\u001b[32m   2750\u001b[39m compile_options = create_compile_options(\n\u001b[32m   2751\u001b[39m     computation, mesh, spmd_lowering, tuple_args, auto_spmd_lowering,\n\u001b[32m   2752\u001b[39m     allow_prop_to_inputs, allow_prop_to_outputs, backend,\n\u001b[32m   2753\u001b[39m     dev, pmap_nreps, compiler_options)\n\u001b[32m   2755\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dispatch.log_elapsed_time(\n\u001b[32m   2756\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFinished XLA compilation of \u001b[39m\u001b[38;5;132;01m{fun_name}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{elapsed_time:.9f}\u001b[39;00m\u001b[33m sec\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2757\u001b[39m     fun_name=name, event=dispatch.BACKEND_COMPILE_EVENT):\n\u001b[32m-> \u001b[39m\u001b[32m2758\u001b[39m   xla_executable = \u001b[43mcompiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_or_get_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2759\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2760\u001b[39m \u001b[43m      \u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2761\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xla_executable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nnsi/lib/python3.13/site-packages/jax/_src/compiler.py:470\u001b[39m, in \u001b[36mcompile_or_get_cached\u001b[39m\u001b[34m(backend, computation, devices, compile_options, host_callbacks, pgle_profiler)\u001b[39m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    469\u001b[39m   log_persistent_cache_miss(module_name, cache_key)\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_and_write_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m      \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nnsi/lib/python3.13/site-packages/jax/_src/compiler.py:687\u001b[39m, in \u001b[36m_compile_and_write_cache\u001b[39m\u001b[34m(backend, computation, compile_options, host_callbacks, module_name, cache_key)\u001b[39m\n\u001b[32m    678\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compile_and_write_cache\u001b[39m(\n\u001b[32m    679\u001b[39m     backend: xc.Client,\n\u001b[32m    680\u001b[39m     computation: ir.Module,\n\u001b[32m   (...)\u001b[39m\u001b[32m    684\u001b[39m     cache_key: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    685\u001b[39m ) -> xc.LoadedExecutable:\n\u001b[32m    686\u001b[39m   start_time = time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m687\u001b[39m   executable = \u001b[43mbackend_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost_callbacks\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m   compile_time = time.monotonic() - start_time\n\u001b[32m    691\u001b[39m   _cache_write(\n\u001b[32m    692\u001b[39m       cache_key, compile_time, module_name, backend, executable, host_callbacks\n\u001b[32m    693\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nnsi/lib/python3.13/site-packages/jax/_src/profiler.py:334\u001b[39m, in \u001b[36mannotate_function.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    331\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    333\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, **decorator_kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nnsi/lib/python3.13/site-packages/jax/_src/compiler.py:321\u001b[39m, in \u001b[36mbackend_compile\u001b[39m\u001b[34m(backend, module, options, host_callbacks)\u001b[39m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m backend.compile(\n\u001b[32m    316\u001b[39m         built_c, compile_options=options, host_callbacks=host_callbacks\n\u001b[32m    317\u001b[39m     )\n\u001b[32m    318\u001b[39m   \u001b[38;5;66;03m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[32m    319\u001b[39m   \u001b[38;5;66;03m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[32m    320\u001b[39m   \u001b[38;5;66;03m# to take in `host_callbacks`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilt_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m xc.XlaRuntimeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    323\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m error_handler \u001b[38;5;129;01min\u001b[39;00m _XLA_RUNTIME_ERROR_HANDLERS:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed=1)\n",
    "\n",
    "utm_generator = utm_data_generator(\n",
    "    rng,\n",
    "    maximum_steps=EXECUTION_STEPS,\n",
    "    maximum_program_length=100,\n",
    "    memory_size=MEMORY_SIZE,\n",
    "    alphabet_size=CHOMSKY_ALPHABET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "chomsky_generator = make_chomsky_generator(rng, use_delimiters=USE_DELIMITERS)\n",
    "\n",
    "def training_loop():\n",
    "    model_sizes = [\n",
    "        \"small\",\n",
    "        \"medium\",\n",
    "        \"large\"\n",
    "    ]\n",
    "\n",
    "    sampling_types = [\n",
    "        SAMPLE_TYPE.RANDOM, \n",
    "        SAMPLE_TYPE.ORIGINAL,\n",
    "        SAMPLE_TYPE.MARKOV\n",
    "    ]\n",
    "\n",
    "    training_steps_map = {\n",
    "        \"small\": 20000,\n",
    "        \"medium\": 2000,\n",
    "        \"large\": 2000\n",
    "    }\n",
    "\n",
    "    for sampling_type in sampling_types:\n",
    "        for model_size in model_sizes:\n",
    "            training_steps = training_steps_map[model_size]\n",
    "            if sampling_type == SAMPLE_TYPE.RANDOM:\n",
    "                training_steps = 0\n",
    "            \n",
    "            params, loss, eval_losses, eval_accs, eval_final_accs = train_transformer_decoder(\n",
    "                data_generator=utm_generator,\n",
    "                training_steps=training_steps,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                log_every=10,\n",
    "                with_markov=(sampling_type == SAMPLE_TYPE.MARKOV),\n",
    "                size=model_size,\n",
    "                eval_data_generator=chomsky_generator,\n",
    "            )\n",
    "            logging.info(\"Final loss: %f\", loss)\n",
    "\n",
    "            if sampling_type == SAMPLE_TYPE.ORIGINAL:\n",
    "                SUFFIX = 'original'\n",
    "            elif sampling_type == SAMPLE_TYPE.MARKOV:\n",
    "                SUFFIX = 'markov'\n",
    "            else:\n",
    "                SUFFIX = 'random'\n",
    "\n",
    "            file_name = f\"params_{SUFFIX}_transformer_{model_size}.npz\"\n",
    "            save_params(params, file_name)\n",
    "\n",
    "            logging.info(f\"Parameters saved in file {file_name}\")\n",
    "\n",
    "            # Create a pandas DataFrame from the evaluation metrics\n",
    "            eval_data = {\n",
    "                \"eval_losses\": eval_losses,\n",
    "                \"eval_accs\": eval_accs,\n",
    "                \"eval_final_accs\": eval_final_accs,\n",
    "            }\n",
    "            eval_df = pd.DataFrame(eval_data)\n",
    "\n",
    "            # Save the DataFrame to a CSV file\n",
    "            metrics_name = f\"metrics_{SUFFIX}_transformer_{model_size}.csv\"\n",
    "            if sampling_type != SAMPLE_TYPE.RANDOM:\n",
    "                eval_df.to_csv(metrics_name, index=False)\n",
    "\n",
    "            logging.info(f\"Evaluation metrics saved to {metrics_name}\")\n",
    "\n",
    "training_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
