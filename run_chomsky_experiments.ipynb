{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import haiku as hk\n",
    "import jax\n",
    "\n",
    "from haiku._src.typing import Mapping\n",
    "from jax._src.basearray import Array\n",
    "\n",
    "from helpers import (\n",
    "    evaluate_transformer_decoder,\n",
    "    make_chomsky_generator,\n",
    "    make_model,\n",
    "    utm_data_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "\n",
    "ORDERED_TASKS = [\n",
    "    # Regular.\n",
    "    \"even_pairs\",\n",
    "    \"modular_arithmetic\",\n",
    "    \"parity_check\",\n",
    "    \"cycle_navigation\",\n",
    "    # Context free.\n",
    "    \"stack_manipulation\",\n",
    "    \"reverse_string\",\n",
    "    \"modular_arithmetic_brackets\",\n",
    "    \"solve_equation\",\n",
    "    # Context sensitive.\n",
    "    \"duplicate_string\",\n",
    "    \"missing_duplicate_string\",\n",
    "    \"odds_first\",\n",
    "    \"binary_addition\",\n",
    "    \"binary_multiplication\",\n",
    "    \"compute_sqrt\",\n",
    "    \"bucket_sort\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_params(\n",
    "    data_generator, params_path: str, batch_size: int = 128\n",
    ") -> hk.Params:\n",
    "    \"\"\"Loads saved model parameters and returns the initialized model and params.\n",
    "\n",
    "    Args:\n",
    "        params_path: Path to the saved .npz file containing model parameters\n",
    "        vocab_size: Size of the vocabulary used by the model\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing (model, params) where model is the initialized Haiku model\n",
    "        and params are the loaded parameters\n",
    "    \"\"\"\n",
    "    # Create the same model configuration as used in training\n",
    "    model = make_model(data_generator)\n",
    "\n",
    "    # Load the saved parameters\n",
    "    loaded = np.load(params_path, allow_pickle=True)\n",
    "    tree_def = loaded[\"tree_def\"].item()  # Get PyTreeDef\n",
    "    flat_params = [loaded[f\"arr_{i}\"] for i in range(len(loaded.files) - 1)]\n",
    "    loaded_params = jax.tree_util.tree_unflatten(tree_def, flat_params)\n",
    "\n",
    "    # Initialize the model with a dummy batch to get the parameter structure\n",
    "    dummy_batch, _ = data_generator.sample_dummy(batch_size)  # Minimal dummy input\n",
    "    dummy_batch = np.argmax(dummy_batch, axis=-1)\n",
    "\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    model.init(rng, dummy_batch)\n",
    "\n",
    "    return loaded_params\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"artifacts/params_markov_old_transformer_large.npz\",\n",
    "    \"artifacts/params_original_old_transformer_large.npz\",\n",
    "    # \"params_markov_transformer_large.npz\", \n",
    "    # \"params_original_transformer_large.npz\",\n",
    "    # \"params_random_initialized_transformer_large.npz\",\n",
    "    # \"params_markov_transformer_medium.npz\", \n",
    "    # \"params_original_transformer_medium.npz\",\n",
    "    # \"params_random_initialized_transformer_medium.npz\",\n",
    "    # \"params_markov_transformer_small.npz\",\n",
    "    # \"params_original_transformer_small.npz\",\n",
    "    # \"params_random_initialized_transformer_small.npz\",\n",
    "]\n",
    "\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "utm_generator = utm_data_generator(rng)\n",
    "\n",
    "# Load the model and parameters\n",
    "model_params: Mapping[str, Mapping[str, Mapping[str, Array]]] = {}\n",
    "for model_path in model_paths:\n",
    "    params: Mapping[str, Mapping[str, Array]] = load_model_params(utm_generator, model_path)\n",
    "    model_params[model_path] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  artifacts/params_markov_old_transformer_large.npz\n",
      "Chomsky Task:  even_pairs\n",
      "even_pairs 0.43663058 0.4367052\n",
      "Model:  artifacts/params_markov_old_transformer_large.npz\n",
      "Chomsky Task:  modular_arithmetic\n",
      "modular_arithmetic 0.17371441 0.17370424\n",
      "Model:  artifacts/params_markov_old_transformer_large.npz\n",
      "Chomsky Task:  parity_check\n",
      "parity_check 0.4399623 0.4399778\n",
      "Model:  artifacts/params_markov_old_transformer_large.npz\n",
      "Chomsky Task:  cycle_navigation\n",
      "cycle_navigation 0.28950483 0.28950673\n",
      "Model:  artifacts/params_markov_old_transformer_large.npz\n",
      "Chomsky Task:  stack_manipulation\n",
      "stack_manipulation 0.33672184 0.32854405\n",
      "Model:  artifacts/params_markov_old_transformer_large.npz\n",
      "Chomsky Task:  reverse_string\n",
      "reverse_string 0.44632584 0.44796854\n",
      "Model:  artifacts/params_markov_old_transformer_large.npz\n",
      "Chomsky Task:  modular_arithmetic_brackets\n",
      "modular_arithmetic_brackets 0.13179725 0.1317888\n",
      "Model:  artifacts/params_markov_old_transformer_large.npz\n",
      "Chomsky Task:  solve_equation\n",
      "solve_equation 0.19959976 0.19961715\n",
      "Model:  artifacts/params_markov_old_transformer_large.npz\n",
      "Chomsky Task:  duplicate_string\n",
      "duplicate_string 0.4365583 0.44253287\n",
      "Model:  artifacts/params_markov_old_transformer_large.npz\n",
      "Chomsky Task:  missing_duplicate_string\n",
      "missing_duplicate_string 0.42566103 0.42560524\n",
      "Model:  artifacts/params_markov_old_transformer_large.npz\n",
      "Chomsky Task:  odds_first\n",
      "odds_first 0.4406314 0.44127807\n",
      "Model:  artifacts/params_markov_old_transformer_large.npz\n",
      "Chomsky Task:  binary_addition\n",
      "binary_addition 0.4337799 0.4329621\n",
      "Model:  artifacts/params_markov_old_transformer_large.npz\n",
      "Chomsky Task:  binary_multiplication\n",
      "binary_multiplication 0.4337225 0.432486\n",
      "Model:  artifacts/params_markov_old_transformer_large.npz\n",
      "Chomsky Task:  compute_sqrt\n",
      "Failed to evaluate task compute_sqrt empty range in randrange(1, 0)\n",
      "Model:  artifacts/params_markov_old_transformer_large.npz\n",
      "Chomsky Task:  bucket_sort\n",
      "bucket_sort 0.23749211 0.23195553\n",
      "Model:  artifacts/params_original_old_transformer_large.npz\n",
      "Chomsky Task:  even_pairs\n"
     ]
    }
   ],
   "source": [
    "get_size_from_model_path = lambda path: \"large\" if \"large\" in path else \"medium\" if \"medium\" in path else \"small\" if \"small\" in path else \"unknown\"\n",
    "for model_str, params in model_params.items():\n",
    "    for task in ORDERED_TASKS:\n",
    "        print(\"Model: \", model_str)\n",
    "        print(\"Chomsky Task: \", task)\n",
    "        try:\n",
    "            # max_input_length = 256 is arbitrary, I dont think this is explicitly defined in the paper.\n",
    "            chomsky_generator = make_chomsky_generator(\n",
    "                rng, task_str=task\n",
    "            )\n",
    "            regret, total_accuracy, total_final_accuracy = evaluate_transformer_decoder(\n",
    "                chomsky_generator, params, utm_generator, num_batches=10, size=get_size_from_model_path(model_str)\n",
    "            )\n",
    "            print(task, total_accuracy, total_final_accuracy)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to evaluate task\", task, e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
