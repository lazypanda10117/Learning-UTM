{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import functools\n",
    "\n",
    "from haiku._src.typing import Mapping\n",
    "from jax._src.basearray import Array\n",
    "\n",
    "from helpers import (\n",
    "    evaluate_transformer_decoder,\n",
    "    make_chomsky_generator,\n",
    "    make_model,\n",
    "    utm_data_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "\n",
    "ORDERED_TASKS = [\n",
    "    # Regular.\n",
    "    \"even_pairs\",\n",
    "    \"modular_arithmetic\",\n",
    "    \"parity_check\",\n",
    "    \"cycle_navigation\",\n",
    "    # Context free.\n",
    "    \"stack_manipulation\",\n",
    "    \"reverse_string\",\n",
    "    \"modular_arithmetic_brackets\",\n",
    "    \"solve_equation\",\n",
    "    # Context sensitive.\n",
    "    \"duplicate_string\",\n",
    "    \"missing_duplicate_string\",\n",
    "    \"odds_first\",\n",
    "    \"binary_addition\",\n",
    "    \"binary_multiplication\",\n",
    "    \"compute_sqrt\",\n",
    "    \"bucket_sort\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_params(\n",
    "    data_generator, params_path: str, batch_size: int = 128\n",
    ") -> hk.Params:\n",
    "    \"\"\"Loads saved model parameters and returns the initialized model and params.\n",
    "\n",
    "    Args:\n",
    "        params_path: Path to the saved .npz file containing model parameters\n",
    "        vocab_size: Size of the vocabulary used by the model\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing (model, params) where model is the initialized Haiku model\n",
    "        and params are the loaded parameters\n",
    "    \"\"\"\n",
    "    # Create the same model configuration as used in training\n",
    "    model = make_model(data_generator)\n",
    "\n",
    "    # Load the saved parameters\n",
    "    loaded = np.load(params_path, allow_pickle=True)\n",
    "    tree_def = loaded[\"tree_def\"].item()  # Get PyTreeDef\n",
    "    flat_params = [loaded[f\"arr_{i}\"] for i in range(len(loaded.files) - 1)]\n",
    "    loaded_params = jax.tree_util.tree_unflatten(tree_def, flat_params)\n",
    "\n",
    "    # Initialize the model with a dummy batch to get the parameter structure\n",
    "    dummy_batch, _ = data_generator.sample_dummy(batch_size)  # Minimal dummy input\n",
    "    dummy_batch = np.argmax(dummy_batch, axis=-1)\n",
    "\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    model.init(rng, dummy_batch)\n",
    "\n",
    "    return loaded_params\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"artifacts/params_markov_old.npz\",\n",
    "    \"artifacts/params_original_old.npz\",\n",
    "    # \"params_markov_transformer_large.npz\", \n",
    "    # \"params_original_transformer_large.npz\",\n",
    "    # \"params_random_initialized_transformer_large.npz\",\n",
    "    # \"params_markov_transformer_medium.npz\", \n",
    "    # \"params_original_transformer_medium.npz\",\n",
    "    # \"params_random_initialized_transformer_medium.npz\",\n",
    "    # \"params_markov_transformer_small.npz\",\n",
    "    # \"params_original_transformer_small.npz\",\n",
    "    # \"params_random_initialized_transformer_small.npz\",\n",
    "]\n",
    "\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "utm_generator = utm_data_generator(rng)\n",
    "\n",
    "# Load the model and parameters\n",
    "model_params: Mapping[str, Mapping[str, Mapping[str, Array]]] = {}\n",
    "for model_path in model_paths:\n",
    "    params: Mapping[str, Mapping[str, Array]] = load_model_params(utm_generator, model_path)\n",
    "    model_params[model_path] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chomsky Task: even_pairs\n",
      "even_pairs 0.42429695 0.42429194\n",
      "Chomsky Task: modular_arithmetic\n",
      "Failed to evaluate task modular_arithmetic all the input array dimensions except for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 7 and the array at index 1 has size 11\n",
      "Chomsky Task: parity_check\n",
      "parity_check 0.42754906 0.42755023\n",
      "Chomsky Task: cycle_navigation\n",
      "Failed to evaluate task cycle_navigation all the input array dimensions except for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 5 and the array at index 1 has size 7\n",
      "Chomsky Task: stack_manipulation\n",
      "Failed to evaluate task stack_manipulation all the input array dimensions except for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 5 and the array at index 1 has size 7\n",
      "Chomsky Task: reverse_string\n",
      "reverse_string 0.43992084 0.44297442\n",
      "Chomsky Task: modular_arithmetic_brackets\n",
      "Failed to evaluate task modular_arithmetic_brackets all the input array dimensions except for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 7 and the array at index 1 has size 13\n",
      "Chomsky Task: solve_equation\n",
      "Failed to evaluate task solve_equation all the input array dimensions except for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 7 and the array at index 1 has size 13\n",
      "Chomsky Task: duplicate_string\n",
      "duplicate_string 0.43484825 0.43865362\n",
      "Chomsky Task: missing_duplicate_string\n",
      "Failed to evaluate task missing_duplicate_string all the input array dimensions except for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 4 and the array at index 1 has size 6\n",
      "Chomsky Task: odds_first\n",
      "odds_first 0.42229193 0.42071575\n",
      "Chomsky Task: binary_addition\n",
      "binary_addition 0.42486876 0.42318183\n",
      "Chomsky Task: binary_multiplication\n",
      "binary_multiplication 0.4277622 0.42528924\n",
      "Chomsky Task: compute_sqrt\n",
      "Failed to evaluate task compute_sqrt empty range in randrange(1, 0)\n",
      "Chomsky Task: bucket_sort\n",
      "bucket_sort 0.23868115 0.24146676\n"
     ]
    }
   ],
   "source": [
    "for task in ORDERED_TASKS:\n",
    "    print(\"Chomsky Task:\", task)\n",
    "    try:\n",
    "        # max_input_length = 256 is arbitrary, I dont think this is explicitly defined in the paper.\n",
    "        chomsky_generator = make_chomsky_generator(\n",
    "            rng, task_str=task\n",
    "        )\n",
    "        regret, total_accuracy, total_final_accuracy = evaluate_transformer_decoder(\n",
    "            chomsky_generator, params, utm_generator\n",
    "        )\n",
    "        print(task, total_accuracy, total_final_accuracy)\n",
    "    except Exception as e:\n",
    "        print(\"Failed to evaluate task\", task, e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
